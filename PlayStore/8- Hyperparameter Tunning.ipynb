{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "tutorial-recorder",
   "metadata": {},
   "source": [
    "# 8- Hyperparameter Tunning\n",
    "\n",
    "### def name_f(parm1, parm2, param3)\n",
    "    pass\n",
    "    \n",
    "**1- Model parameter**\n",
    "\n",
    "    * No es una entrada del usuario\n",
    "    * Es un parametro resultado del modelo en sí (por ej. la pendiente o el intercepto)\n",
    "\n",
    "**2- Model Hyperparameter**\n",
    "\n",
    "    * Es una entrada del usuario\n",
    "    * Learning rate / K nearest neighbors\n",
    "    \n",
    "### **2 opciones para hacer Hyperparameter Tunning:**\n",
    "\n",
    "    1- Random Search (sklearn)\n",
    "        ## KNN == Vecinos más cercanos (5,1,80,15)\n",
    "    2- Grid Search\n",
    "        ##KNN == Vecinos más cercanos range(1, 50, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "preceding-musical",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "import pandas as pd\n",
    "# def get_datasets():\n",
    "#     X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, \n",
    "#                               n_redundant=5, random_state=1)\n",
    "#     return X, y\n",
    "# X,y = get_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "turkish-stick",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "stopped-median",
   "metadata": {},
   "outputs": [],
   "source": [
    "##definir los hyperparametros del modelo\n",
    "# model = KNeighborsClassifier()\n",
    "# n_neighbors = range(1, 20)\n",
    "# weights = ['uniform', 'distance']\n",
    "# distance = ['euclidean', 'manhattan', 'minkowski']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "individual-robert",
   "metadata": {},
   "outputs": [],
   "source": [
    "##definir GridSearch\n",
    "\n",
    "# grid = dict(n_neighbors = n_neighbors, weights = weights, metric = distance)\n",
    "# cv = KFold(n_splits=5)\n",
    "# grid_search = GridSearchCV(estimator = model, param_grid = grid, n_jobs=-1, cv=cv, scoring= 'f1')\n",
    "# grid_result = grid_search.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "familiar-radiation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "varied-terror",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_result.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "level-showcase",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_result.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "artistic-border",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_oversample = pd.read_csv('datasets/X_oversample.csv')\n",
    "y_oversample = pd.read_csv('datasets/y_oversample.csv')\n",
    "X_test = pd.read_csv('datasets/TestEncoded.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "floral-logic",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "moved-district",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(params, random = False):\n",
    "    \n",
    "    ##XGBoost standard\n",
    "    xgb = XGBClassifier(booster = 'gbtree', objective= 'binary:logistic', random_state = 2)\n",
    "    \n",
    "    ##KFold\n",
    "    kfold = KFold(n_splits=5)\n",
    "    \n",
    "    ## if statement ocn random o sin random\n",
    "    if random: \n",
    "        grid = RandomizedSearchCV(xgb, params, cv = kfold, n_iter=5, n_jobs=-1)\n",
    "    else:\n",
    "        grid = RandomizedSearchCV(xgb, params, cv = kfold , n_jobs=-1)\n",
    "        \n",
    "    ## entrenar el modelo en el grid\n",
    "    grid.fit(X_oversample, y_oversample)\n",
    "    \n",
    "    ## obtener e imprimir los mejores parametros\n",
    "    best_params= grid.best_params_\n",
    "    print(best_params)\n",
    "    \n",
    "    ##obtener e imprimir mejor score\n",
    "    best_score = grid.best_score_\n",
    "    \n",
    "    print('best score: ', best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "personalized-petroleum",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(params, random=False):\n",
    "    ## XGBoost standard\n",
    "    xgb = XGBClassifier(booster='gbtree', objective='binary:logistic', random_state=2)\n",
    "    ## Kfold\n",
    "    kfold = KFold(n_splits=5)\n",
    "    ## if statement con Random o sin Random\n",
    "    if random:\n",
    "        grid = RandomizedSearchCV(xgb, params, cv=kfold, n_iter=5, n_jobs=-1)\n",
    "    else:\n",
    "        grid = GridSearchCV(xgb, params, cv=kfold, n_jobs=-1)\n",
    "    ## entrenar el modelo en el grid\n",
    "    grid.fit(X_oversample, y_oversample)\n",
    "    ## obtener e imprimir los mejores parametros\n",
    "    best_params = grid.best_params_\n",
    "    print(best_params)\n",
    "    ## obtener e imprimir los mejores scores\n",
    "    best_score = grid.best_score_\n",
    "    print(\"best score\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "insured-speaker",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\porta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\porta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:39:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"n_stimators\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[20:39:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "{'n_stimators': 2}\n",
      "best score 0.8082176541749503\n"
     ]
    }
   ],
   "source": [
    "grid_search(params = {'n_stimators': [2,25,50,75,100] })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cellular-corps",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:40:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "{'max_depth': 8, 'n_estimators': 100}\n",
      "best score 0.8108818364990361\n"
     ]
    }
   ],
   "source": [
    "grid_search(params = {'max_depth': [1,2,3,4,5,6,7,8], 'n_estimators':[100]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "qualified-photography",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:41:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "{'learning_rate': 0.5, 'max_depth': 8, 'n_estimators': 100}\n",
      "best score 0.8127356999894658\n"
     ]
    }
   ],
   "source": [
    "grid_search(params = {'learning_rate':[0.01,0.05, 0.1, 0.2, 0.3, 0.4, 0.5], 'max_depth': [8], 'n_estimators':[100]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "unexpected-disclosure",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:44:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "{'learning_rate': 0.5, 'max_depth': 8, 'min_child_weight': 1, 'n_estimators': 100}\n",
      "best score 0.8127356999894658\n"
     ]
    }
   ],
   "source": [
    "grid_search(params = {'min_child_weight': [1,2,3,4,5],'learning_rate':[0.5], 'max_depth': [8], 'n_estimators':[100]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "younger-venezuela",
   "metadata": {},
   "outputs": [],
   "source": [
    "model= XGBClassifier(booster= 'gbtree',objective='binary:logistic', random_state= 2 ,min_child_weight = 1,learning_rate=0.5 , max_depth= 8, n_estimators= 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "black-fiction",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\porta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\porta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:50:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.5, max_delta_step=0, max_depth=8,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=12, num_parallel_tree=1, random_state=2,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_oversample,y_oversample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "mediterranean-program",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "collect-detail",
   "metadata": {},
   "outputs": [],
   "source": [
    "def results_to_csv(file_name, y_pred):\n",
    "    model = pd.DataFrame({'id':list(range(1,len(y_pred)+1)),\n",
    "                        'rating': y_pred})\n",
    "    model.to_csv(f'results/{file_name}.csv', index = False)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "integral-missile",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1443</th>\n",
       "      <td>1444</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1444</th>\n",
       "      <td>1445</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1445</th>\n",
       "      <td>1446</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1446</th>\n",
       "      <td>1447</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1447</th>\n",
       "      <td>1448</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1448 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  rating\n",
       "0        1     0.0\n",
       "1        2     1.0\n",
       "2        3     0.0\n",
       "3        4     1.0\n",
       "4        5     1.0\n",
       "...    ...     ...\n",
       "1443  1444     1.0\n",
       "1444  1445     1.0\n",
       "1445  1446     1.0\n",
       "1446  1447     0.0\n",
       "1447  1448     1.0\n",
       "\n",
       "[1448 rows x 2 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_to_csv(\"XGBoost-HyperparameterTunning-2\", y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "planned-steering",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
